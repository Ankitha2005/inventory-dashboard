{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002ee39b-bc1c-48d7-8c63-1244e3b2ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purpose: Train a simple Two-Tower retriever (PyTorch) using `data/events.csv` + `data/catalog.csv`, save model + item embeddings for later pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9951a487-4962-43b6-83db-f94775a0629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "#(imports, paths, small configs)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle, os\n",
    "\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "DATA_DIR = BASE / \"data\"\n",
    "EVENTS_CSV = DATA_DIR / \"events.csv\"\n",
    "CATALOG_CSV = DATA_DIR / \"catalog.csv\"\n",
    "OUT_DIR = BASE / \"models\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# quick config\n",
    "EMB_DIM = 64\n",
    "BATCH = 512\n",
    "EPOCHS = 3\n",
    "LR = 1e-3\n",
    "TEMPERATURE = 0.07\n",
    "\n",
    "print(EVENTS_CSV.exists(), CATALOG_CSV.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c348531e-e961-42d8-a812-44bfa45b6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users,items,train_rows,test_rows: 97809 8381 302191 97809\n"
     ]
    }
   ],
   "source": [
    "#(build mappings and train/test split — leave-one-out)\n",
    "events = pd.read_csv(EVENTS_CSV, parse_dates=['ts'], low_memory=False)\n",
    "catalog = pd.read_csv(CATALOG_CSV)\n",
    "# map ids to indices\n",
    "users = sorted(events['user_id'].dropna().unique())\n",
    "items = sorted(catalog['item_id'].dropna().unique())\n",
    "user2idx = {u:i for i,u in enumerate(users)}\n",
    "item2idx = {it:i for i,it in enumerate(items)}\n",
    "idx2item = {v:k for k,v in item2idx.items()}\n",
    "\n",
    "# only keep interactions that map to our catalog items\n",
    "events = events[events['item_id'].isin(item2idx)].copy()\n",
    "events['user_idx'] = events['user_id'].map(user2idx)\n",
    "events['item_idx'] = events['item_id'].map(item2idx)\n",
    "events = events.sort_values(['user_idx','ts'])\n",
    "\n",
    "# leave-one-out: last interaction per user -> test\n",
    "last = events.groupby('user_idx')['ts'].idxmax()\n",
    "test_df = events.loc[last].copy()\n",
    "train_df = events.drop(last).copy().reset_index(drop=True)\n",
    "print(\"users,items,train_rows,test_rows:\", len(users), len(items), train_df.shape[0], test_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301a93b5-0623-4e9c-8d57-db3421dcf086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(PyTorch Dataset + TwoTower model)\n",
    "class RecDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.u = df['user_idx'].astype(int).values\n",
    "        self.i = df['item_idx'].astype(int).values\n",
    "    def __len__(self): return len(self.u)\n",
    "    def __getitem__(self, idx): return self.u[idx], self.i[idx]\n",
    "\n",
    "class TwoTower(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        self.user_mlp = nn.Sequential(nn.Linear(emb_dim, emb_dim), nn.ReLU(), nn.Linear(emb_dim, emb_dim))\n",
    "        self.item_mlp = nn.Sequential(nn.Linear(emb_dim, emb_dim), nn.ReLU(), nn.Linear(emb_dim, emb_dim))\n",
    "    def forward_user(self, u): return self.user_mlp(self.user_emb(u))\n",
    "    def forward_item(self, i): return self.item_mlp(self.item_emb(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de45cae3-6f78-4ea6-9edd-63ed0adcf267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg_loss=6.5746\n",
      "Saved checkpoint and item embeddings\n",
      "Epoch 2 avg_loss=6.2184\n",
      "Saved checkpoint and item embeddings\n",
      "Epoch 3 avg_loss=6.1763\n",
      "Saved checkpoint and item embeddings\n"
     ]
    }
   ],
   "source": [
    "#(training loop with in-batch negatives + save artifacts)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_users = len(user2idx); n_items = len(item2idx)\n",
    "model = TwoTower(n_users, n_items, emb_dim=EMB_DIM).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(RecDataset(train_df), batch_size=BATCH, shuffle=True, drop_last=True)\n",
    "\n",
    "def compute_item_embeddings(model, device, batch=1024):\n",
    "    model.eval()\n",
    "    embs = []\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, n_items, batch):\n",
    "            ids = torch.arange(start, min(n_items, start+batch), dtype=torch.long, device=device)\n",
    "            embs.append(model.forward_item(ids).cpu().numpy())\n",
    "    return np.vstack(embs)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for users_batch, items_batch in train_loader:\n",
    "        users_batch = users_batch.to(device)\n",
    "        items_batch = items_batch.to(device)\n",
    "        u_vec = model.forward_user(users_batch)          # (B,D)\n",
    "        i_vec = model.forward_item(items_batch)          # (B,D)\n",
    "        logits = torch.matmul(u_vec, i_vec.t()) / TEMPERATURE    # (B,B)\n",
    "        labels = torch.arange(logits.size(0), device=device)\n",
    "        loss = ce(logits, labels)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} avg_loss={total_loss/len(train_loader):.4f}\")\n",
    "    # checkpoint item embeddings\n",
    "    item_embs = compute_item_embeddings(model, device)\n",
    "    np.save(OUT_DIR / \"item_embeddings.npy\", item_embs)\n",
    "    torch.save(model.state_dict(), OUT_DIR / \"two_tower.pth\")\n",
    "    with open(OUT_DIR / \"mappings.pkl\", \"wb\") as f:\n",
    "        pickle.dump({'user2idx':user2idx,'item2idx':item2idx,'idx2item':idx2item}, f)\n",
    "    print(\"Saved checkpoint and item embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c5139d-e370-47c5-b829-381cc5bcb7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example user: A00472881KT6WR48K907X Top-10 items: ['B0002IQ1F8', 'B0002NUECY', 'B0002L2MMG', 'B00004RIPE', 'B0002ZPH7O', 'B0000TFGWS', 'B0006ZSQL4', 'B0007WW69O', 'B0001ZRLRE', 'B00091S0S4']\n"
     ]
    }
   ],
   "source": [
    "# (quick retrieval demo using saved embeddings)\n",
    "import numpy as np\n",
    "item_embs = np.load(OUT_DIR / \"item_embeddings.npy\")\n",
    "with open(OUT_DIR / \"mappings.pkl\",\"rb\") as f: meta = pickle.load(f)\n",
    "u_example = next(iter(meta['user2idx'].keys()))\n",
    "u_idx = torch.LongTensor([meta['user2idx'][u_example]]).to(device)\n",
    "model.load_state_dict(torch.load(OUT_DIR / \"two_tower.pth\", map_location=device))\n",
    "model.to(device).eval()\n",
    "with torch.no_grad():\n",
    "    u_emb = model.forward_user(u_idx).cpu().numpy()[0]\n",
    "scores = item_embs @ u_emb\n",
    "topk = np.argsort(-scores)[:10]\n",
    "print(\"Example user:\", u_example, \"Top-10 items:\", [meta['idx2item'][int(i)] for i in topk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b3ca84-e1c8-49a8-9961-be360f5c3f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 97809/97809 [02:38<00:00, 615.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@50 = 0.0157\n",
      "MRR = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate_retrieval(It will evaluate how useful the loss values are in practice — loss alone won’t tell you if retrieval is good.)\n",
    "import numpy as np, pickle, torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "OUT = BASE / \"models\"\n",
    "DATA = BASE / \"data\"\n",
    "# load artifacts\n",
    "item_embs = np.load(OUT / \"item_embeddings.npy\")   # shape (n_items, D)\n",
    "with open(OUT / \"mappings.pkl\",\"rb\") as f: meta = pickle.load(f)\n",
    "events = __import__(\"pandas\").read_csv(DATA / \"events.csv\", parse_dates=[\"ts\"], low_memory=False)\n",
    "\n",
    "# load model skeleton (recreate TwoTower from your notebook) and weights\n",
    "# paste the TwoTower class definition here if not importable; below assumes it's in the notebook session\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TwoTower(n_users=len(meta['user2idx']), n_items=len(meta['item2idx']), emb_dim=item_embs.shape[1])\n",
    "model.load_state_dict(torch.load(OUT / \"two_tower.pth\", map_location=device))\n",
    "model.to(device).eval()\n",
    "\n",
    "# prepare test users: leave-one-out test (already created earlier as test_df in the notebook)\n",
    "# if test_df not in session, rebuild quickly:\n",
    "events = events[events['item_id'].isin(meta['item2idx'].keys())].copy()\n",
    "events['user_idx'] = events['user_id'].map(meta['user2idx'])\n",
    "events['item_idx'] = events['item_id'].map(meta['item2idx'])\n",
    "events = events.sort_values(['user_idx','ts'])\n",
    "last = events.groupby('user_idx')['ts'].idxmax()\n",
    "test_df = events.loc[last]\n",
    "\n",
    "K = 50\n",
    "hits = 0\n",
    "mrr_total = 0.0\n",
    "total = 0\n",
    "\n",
    "# normalize item_embs for cosine-like inner product\n",
    "item_norm = item_embs / (np.linalg.norm(item_embs, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    u_idx = torch.LongTensor([int(row['user_idx'])]).to(device)\n",
    "    with torch.no_grad():\n",
    "        u_emb = model.forward_user(u_idx).cpu().numpy()[0]\n",
    "    scores = item_norm @ (u_emb / (np.linalg.norm(u_emb)+1e-9))\n",
    "    topk = np.argsort(-scores)[:K]\n",
    "    pos = int(row['item_idx'])\n",
    "    total += 1\n",
    "    if pos in topk:\n",
    "        hits += 1\n",
    "        rank = int(np.where(topk == pos)[0][0]) + 1\n",
    "        mrr_total += 1.0 / rank\n",
    "\n",
    "recall_at_k = hits / total\n",
    "mrr = mrr_total / total\n",
    "print(f\"Recall@{K} = {recall_at_k:.4f}\")\n",
    "print(f\"MRR = {mrr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f63c54c-614b-4223-9607-4fc9e46cf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall@50 = 0.0157 (1.6%) → the correct item appeared in the top-50 recommendations for ~1.6% of users.\n",
    "\n",
    "#MRR = 0.0015 → on average, the correct item ranks very low (closer to bottom of top-K).\n",
    "\n",
    "#This is normal for a first, un-tuned Two-Tower trained on synthetic data (views/purchases randomly generated). It confirms the pipeline works — now we can improve it later with better negative sampling, feature enrichment, or longer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b7af1-8625-4fa8-b7e0-3fc70230d062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
