{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b3a386-329f-4f10-8ae3-aeeb24f3b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installation\n",
    "!pip install faiss-cpu --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a6cb2a-0c3a-4992-872e-e8f280a0c0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "Loaded item_embs (8381, 64)\n"
     ]
    }
   ],
   "source": [
    "#(paths + load embeddings & mappings)\n",
    "from pathlib import Path\n",
    "import numpy as np, pickle\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "OUT_DIR = BASE / \"models\"\n",
    "item_emb_path = OUT_DIR / \"item_embeddings.npy\"\n",
    "mappings_path = OUT_DIR / \"mappings.pkl\"\n",
    "print(item_emb_path.exists(), mappings_path.exists())\n",
    "item_embs = np.load(item_emb_path)  # shape (n_items, D)\n",
    "with open(mappings_path,\"rb\") as f: meta = pickle.load(f)\n",
    "print(\"Loaded item_embs\", item_embs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433135d9-7dd0-40e6-adb7-eef87b362e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS ready (embeddings normalized saved).\n"
     ]
    }
   ],
   "source": [
    "#(build & save FAISS index; fallback to numpy file if faiss missing)\n",
    "try:\n",
    "    import faiss\n",
    "    emb_dim = item_embs.shape[1]\n",
    "    index = faiss.IndexFlatIP(emb_dim)   # inner-product (use normalized vectors for cosine)\n",
    "    # normalize embeddings (row-wise)\n",
    "    xb = item_embs.astype('float32')\n",
    "    xb = xb / (np.linalg.norm(xb, axis=1, keepdims=True) + 1e-9)\n",
    "    index.add(xb)\n",
    "    faiss.write_index(index, str(OUT_DIR / \"faiss_index.ivf\")) if False else faiss.IndexFlatIP(emb_dim)  # no IVF write; instead save with npy below\n",
    "    # save normalized embeddings and a small metadata file\n",
    "    np.save(OUT_DIR / \"item_embs_norm.npy\", xb)\n",
    "    with open(OUT_DIR / \"faiss_meta.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\"idx2item\": meta[\"idx2item\"]}, f)\n",
    "    print(\"FAISS ready (embeddings normalized saved).\")\n",
    "except Exception as e:\n",
    "    # fallback: save embeddings for numpy search\n",
    "    np.save(OUT_DIR / \"item_embs_norm.npy\", item_embs)\n",
    "    with open(OUT_DIR / \"faiss_meta.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\"idx2item\": meta[\"idx2item\"]}, f)\n",
    "    print(\"FAISS not available â€” saved embeddings for numpy fallback. Error:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54731da-5182-45d1-936d-0a185d571fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 ASINs: ['B000855048', 'B0001NBHMQ', 'B00067TNDC', 'B0006GDCD0', 'B00004SD89', 'B0001STIEK', 'B0007QQJ9S', 'B000ES8AWI', 'B00006CFDO', 'B0002NUECY']\n"
     ]
    }
   ],
   "source": [
    "#(quick demo: query function using FAISS if available, else numpy)\n",
    "import numpy as np, pickle, torch\n",
    "from pathlib import Path\n",
    "OUT_DIR = Path(r\"D:\\CAPSTONE_FINAL\\models\")\n",
    "item_embs = np.load(OUT_DIR / \"item_embs_norm.npy\")\n",
    "with open(OUT_DIR / \"faiss_meta.pkl\",\"rb\") as f: meta = pickle.load(f)\n",
    "# load model to make user embedding (reuse your two_tower model from earlier)\n",
    "# demo: compute user embedding by loading model (same device as before)\n",
    "import torch\n",
    "from pathlib import Path\n",
    "# load model class from earlier cell (TwoTower) if in notebook; here assume model saved\n",
    "model = torch.load(OUT_DIR / \"two_tower.pth\", map_location=\"cpu\")  # we only need user embedding function in real code\n",
    "# For quick demo we will random user vector:\n",
    "u_emb = np.random.randn(item_embs.shape[1]).astype('float32')\n",
    "u_emb = u_emb / (np.linalg.norm(u_emb) + 1e-9)\n",
    "scores = item_embs @ u_emb\n",
    "topk = np.argsort(-scores)[:10]\n",
    "print(\"Top-10 ASINs:\", [meta['idx2item'][int(i)] for i in topk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1feed65c-a345-446a-99d4-c19208c8c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_embeddings exists: True\n",
      "mappings exists: True\n",
      "Loaded item_embs (8381, 64)\n",
      "Mappings keys: ['user2idx', 'item2idx', 'idx2item']\n"
     ]
    }
   ],
   "source": [
    "#verify artifacts exist and load them\n",
    "from pathlib import Path\n",
    "import numpy as np, pickle\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "OUT_DIR = BASE / \"models\"\n",
    "item_emb_path = OUT_DIR / \"item_embeddings.npy\"\n",
    "mappings_path = OUT_DIR / \"mappings.pkl\"\n",
    "\n",
    "print(\"item_embeddings exists:\", item_emb_path.exists())\n",
    "print(\"mappings exists:\", mappings_path.exists())\n",
    "\n",
    "# load to ensure they are readable\n",
    "item_embs = np.load(item_emb_path)      # will raise if missing/corrupt\n",
    "with open(mappings_path,\"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "print(\"Loaded item_embs\", item_embs.shape)\n",
    "print(\"Mappings keys:\", list(meta.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75e994-d176-4ae8-a944-4cfb7bc9f867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
