{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9826531-b976-4777-8d0d-fee27820daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purpose: run a transformer sentiment model over data/reviews.csv, compute per-item aggregates, and save data/item_review_sentiment.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e730b33-2bec-401c-a43d-db854b34efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CAPSTONE_FINAL\\venv311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch --quiet\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "DATA = BASE / \"data\"\n",
    "REVIEWS = DATA / \"reviews.csv\"\n",
    "OUT = DATA / \"item_review_sentiment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7853cf-e46c-40a4-9c3d-a68f55dc43de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>528881469</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>528881469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>528881469</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>528881469</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>528881469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id    item_id  rating  \\\n",
       "0   AO94DHGC771SJ  528881469     5.0   \n",
       "1   AMO214LNFCEI4  528881469     1.0   \n",
       "2  A3N7T0DY83Y4IG  528881469     3.0   \n",
       "3  A1H8PY3QHMQQA0  528881469     2.0   \n",
       "4  A24EV6RXELQZ63  528881469     1.0   \n",
       "\n",
       "                                         review_text  \n",
       "0  We got this GPS for my husband who is an (OTR)...  \n",
       "1  I'm a professional OTR truck driver, and I bou...  \n",
       "2  Well, what can I say.  I've had this unit in m...  \n",
       "3  Not going to write a long review, even thought...  \n",
       "4  I've had mine for a year and here's what we go...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#quick preview + small sample test\n",
    "# quick peek (to confirm file loads and text column)\n",
    "reviews = pd.read_csv(REVIEWS, usecols=[\"user_id\",\"item_id\",\"rating\",\"review_text\"], nrows=5)\n",
    "display(reviews)\n",
    "# now load full file but lazily (we will iterate in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29a6780-ea97-4721-bb29-c04cc71c4280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ready (framework forced to PyTorch): <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x0000023887BD5290>\n"
     ]
    }
   ],
   "source": [
    "# create a sentiment pipeline (uses distilbert SST-2 model)\n",
    "# force PyTorch backend for the pipeline\n",
    "from transformers import pipeline\n",
    "# ensure PyTorch is used (avoid TF import)\n",
    "sentiment = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=-1,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "print(\"Pipeline ready (framework forced to PyTorch):\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455eeb98-6c33-491b-acf8-3a789fb020c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ready. max_tokens: 512\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Force PyTorch framework so transformers won't try to import TF/Keras\n",
    "sentiment = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_name,\n",
    "    framework=\"pt\",   # <<< force PyTorch, prevents TF import\n",
    "    device=-1         # CPU; set device=0 to use GPU if available\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "max_tokens = getattr(tokenizer, \"model_max_length\", 512)\n",
    "print(\"Pipeline ready. max_tokens:\", max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd7b255-e89e-4803-b61a-8423c6466293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pickle, time, os\n",
    "\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "DATA = BASE / \"data\"\n",
    "REVIEWS = DATA / \"reviews.csv\"\n",
    "OUT = DATA / \"item_review_sentiment_vader.csv\"\n",
    "CHECKPOINT_PICKLE = DATA / \"sentiment_checkpoint_vader.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc6693e-d68f-4939-8d77-8f769314aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 1it [00:23, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 done. processed_global=19991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 2it [00:48, 24.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 done. processed_global=39987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 3it [01:16, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 done. processed_global=59981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 4it [01:44, 26.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 done. processed_global=79963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 5it [02:17, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4 done. processed_global=99956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 6it [02:39, 26.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5 done. processed_global=119946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 7it [03:14, 29.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 6 done. processed_global=139933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 8it [03:47, 30.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 7 done. processed_global=159925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 9it [04:21, 31.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8 done. processed_global=179918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VELAGALA ANKITHA\\AppData\\Local\\Temp\\ipykernel_21540\\1916225224.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
      "Reading review chunks: 10it [04:58, 29.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 9 done. processed_global=199909\n",
      "Saved sentiment aggregates -> D:\\CAPSTONE_FINAL\\data\\item_review_sentiment_vader.csv ; shape = (8381, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "batch_size = 1000      # rows processed at once from chunk; adjust to taste\n",
    "chunksize = 20000      # pandas chunk size when reading file\n",
    "CHECKPOINT_N = 200000   # persist every N processed rows (increase/decrease as needed)\n",
    "\n",
    "# initialize\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "items = {}             # item_id -> aggregation dict\n",
    "processed_global = 0\n",
    "\n",
    "# resume from checkpoint if exists\n",
    "if CHECKPOINT_PICKLE.exists():\n",
    "    print(\"Found checkpoint — resuming.\")\n",
    "    with open(CHECKPOINT_PICKLE,\"rb\") as f:\n",
    "        ck = pickle.load(f)\n",
    "        items = ck.get(\"items\", {})\n",
    "        processed_global = ck.get(\"processed_global\", 0)\n",
    "    print(f\"Resuming: previously processed ~{processed_global} reviews, items tracked = {len(items)}\")\n",
    "\n",
    "start_time = time.time()\n",
    "reader = pd.read_csv(REVIEWS, usecols=[\"item_id\",\"rating\",\"review_text\"], chunksize=chunksize, low_memory=False)\n",
    "\n",
    "for chunk_idx, chunk in enumerate(tqdm(reader, desc=\"Reading review chunks\")):\n",
    "    # drop rows missing key fields\n",
    "    chunk = chunk.dropna(subset=[\"item_id\",\"review_text\"])\n",
    "    # lightweight cleaning\n",
    "    chunk[\"review_text\"] = chunk[\"review_text\"].astype(str).str.replace(\"\\n\",\" \", regex=False).str.strip()\n",
    "    # process in batches of rows to control memory and checkpoint frequency\n",
    "    n = len(chunk)\n",
    "    for start in range(0, n, batch_size):\n",
    "        sub = chunk.iloc[start:start+batch_size]\n",
    "        # compute sentiments\n",
    "        for row in sub.itertuples(index=False):\n",
    "            iid = row.item_id\n",
    "            txt = row.review_text\n",
    "            try:\n",
    "                score = analyzer.polarity_scores(txt)[\"compound\"]    # range [-1,1]\n",
    "            except Exception:\n",
    "                score = 0.0\n",
    "            # map compound -> pos_prob approx (0..1)\n",
    "            # simple mapping: (compound + 1)/2\n",
    "            pos_prob = float((score + 1.0) / 2.0)\n",
    "\n",
    "            # rating fallback\n",
    "            r = 0.0\n",
    "            if pd.notna(row.rating):\n",
    "                try:\n",
    "                    r = float(row.rating)\n",
    "                except Exception:\n",
    "                    r = 0.0\n",
    "\n",
    "            rec = items.setdefault(iid, {\"count\":0, \"sum_pos_prob\":0.0, \"sum_rating\":0.0, \"pos_count\":0, \"neg_count\":0})\n",
    "            rec[\"count\"] += 1\n",
    "            rec[\"sum_pos_prob\"] += pos_prob\n",
    "            rec[\"sum_rating\"] += r\n",
    "            if pos_prob >= 0.6:\n",
    "                rec[\"pos_count\"] += 1\n",
    "            elif pos_prob <= 0.4:\n",
    "                rec[\"neg_count\"] += 1\n",
    "\n",
    "        processed_global += len(sub)\n",
    "\n",
    "        # checkpoint periodically\n",
    "        if processed_global % CHECKPOINT_N < batch_size:\n",
    "            with open(CHECKPOINT_PICKLE, \"wb\") as f:\n",
    "                pickle.dump({\"items\": items, \"processed_global\": processed_global}, f)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"[checkpoint] processed={processed_global} elapsed={elapsed:.1f}s items_tracked={len(items)}\")\n",
    "\n",
    "    # chunk finished\n",
    "    print(f\"Chunk {chunk_idx} done. processed_global={processed_global}\")\n",
    "\n",
    "# build DataFrame & save final\n",
    "rows = []\n",
    "for iid, v in items.items():\n",
    "    cnt = v[\"count\"]\n",
    "    rows.append({\n",
    "        \"item_id\": iid,\n",
    "        \"review_count\": cnt,\n",
    "        \"avg_pos_prob\": v[\"sum_pos_prob\"]/cnt if cnt>0 else 0.0,\n",
    "        \"pos_ratio\": v[\"pos_count\"]/cnt if cnt>0 else 0.0,\n",
    "        \"neg_ratio\": v[\"neg_count\"]/cnt if cnt>0 else 0.0,\n",
    "        \"avg_rating\": v[\"sum_rating\"]/cnt if cnt>0 else np.nan\n",
    "    })\n",
    "\n",
    "sent_df = pd.DataFrame(rows).sort_values(\"review_count\", ascending=False).reset_index(drop=True)\n",
    "sent_df.to_csv(OUT, index=False)\n",
    "print(f\"Saved sentiment aggregates -> {OUT} ; shape = {sent_df.shape}\")\n",
    "\n",
    "# cleanup checkpoint if exists\n",
    "if CHECKPOINT_PICKLE.exists():\n",
    "    os.remove(CHECKPOINT_PICKLE)\n",
    "    print(\"Removed checkpoint file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a4defd-fd4e-44ac-bcbb-911a2ad4b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why VADER? Very fast, rule-based, no GPU required. Good baseline for product review sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004cb33b-4cc2-4a52-a389-1873e2d6938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07_merge_sentiment_inventory\n",
    "#Purpose: Merge item_review_sentiment_vader.csv (review insights) with item_inventory_score.csv (forecast metrics)  → produce item_feature_master.csv for reranker / recommendation training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85341543-c887-4607-ae2f-fe02f74beedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files exist:\n",
      "item_review_sentiment_vader.csv -> True\n",
      "item_inventory_score.csv -> True\n"
     ]
    }
   ],
   "source": [
    "#setup and paths\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(r\"D:\\CAPSTONE_FINAL\")\n",
    "DATA = BASE / \"data\"\n",
    "\n",
    "SENT_PATH = DATA / \"item_review_sentiment_vader.csv\"\n",
    "INV_PATH = DATA / \"item_inventory_score.csv\"\n",
    "OUT_PATH = DATA / \"item_feature_master.csv\"\n",
    "\n",
    "print(\"Files exist:\")\n",
    "for p in [SENT_PATH, INV_PATH]:\n",
    "    print(p.name, \"->\", p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41abb44-288a-4123-a043-c38776d74e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment shape: (8381, 6)\n",
      "Inventory shape: (200, 4)\n",
      "Merged shape: (0, 9)\n",
      " Saved merged dataset -> D:\\CAPSTONE_FINAL\\data\\item_feature_master.csv ; shape = (0, 9)\n"
     ]
    }
   ],
   "source": [
    "#load and merge\n",
    "# Load both datasets\n",
    "sent_df = pd.read_csv(SENT_PATH)\n",
    "inv_df = pd.read_csv(INV_PATH)\n",
    "\n",
    "print(\"Sentiment shape:\", sent_df.shape)\n",
    "print(\"Inventory shape:\", inv_df.shape)\n",
    "\n",
    "# Merge on item_id\n",
    "merged = sent_df.merge(inv_df, on=\"item_id\", how=\"inner\")\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "\n",
    "# Save merged master file\n",
    "merged.to_csv(OUT_PATH, index=False)\n",
    "print(f\" Saved merged dataset -> {OUT_PATH} ; shape = {merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0901de00-6565-4023-8c34-710330261834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment shape: (8381, 6)\n",
      "Inventory shape: (200, 4)\n",
      "\n",
      "Sentiment item_id sample: ['B0002L5R78', 'B000BQ7GW8', 'B00007E7JU', 'B00004ZCJE', 'B0001FTVEK']\n",
      "Inventory item_id sample: ['FOODS_1_029', 'FOODS_1_050', 'FOODS_1_077', 'FOODS_1_106', 'FOODS_1_111']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(r\"D:\\CAPSTONE_FINAL\\data\")\n",
    "\n",
    "# load both files\n",
    "sentiment_df = pd.read_csv(DATA / \"item_review_sentiment_vader.csv\")\n",
    "forecast_df = pd.read_csv(DATA / \"item_inventory_score.csv\")\n",
    "\n",
    "print(\"Sentiment shape:\", sentiment_df.shape)\n",
    "print(\"Inventory shape:\", forecast_df.shape)\n",
    "\n",
    "# show first few IDs to inspect format\n",
    "print(\"\\nSentiment item_id sample:\", sentiment_df[\"item_id\"].head().tolist())\n",
    "print(\"Inventory item_id sample:\", forecast_df[\"item_id\"].head().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac8e1b5-47d5-423a-8025-e980cec6e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent shape: (8381, 6)\n",
      "inv  shape: (200, 4)\n",
      "\n",
      "DTypes:\n",
      "item_id          object\n",
      "review_count      int64\n",
      "avg_pos_prob    float64\n",
      "pos_ratio       float64\n",
      "neg_ratio       float64\n",
      "avg_rating      float64\n",
      "dtype: object\n",
      "item_id               object\n",
      "pred_next_28         float64\n",
      "initial_inventory    float64\n",
      "inventory_score      float64\n",
      "dtype: object\n",
      "\n",
      "Sample sentiment item_id (first 20):\n",
      "['B0002L5R78', 'B000BQ7GW8', 'B00007E7JU', 'B00004ZCJE', 'B0001FTVEK', 'B000A6PPOK', 'B00005T3G0', 'B000CKVOOY', 'B00007M1TZ', 'B00017LSPI', 'B00009R6TA', 'B0000BZL1P', 'B0007MXZB2', 'B00007EDZG', 'B000BTL0OA', 'B000B9RI14', 'B00006RVPW', 'B000652M6Y', 'B00004T8R2', 'B000BKJZ9Q']\n",
      "\n",
      "Sample inventory item_id (first 20):\n",
      "['FOODS_1_029', 'FOODS_1_050', 'FOODS_1_077', 'FOODS_1_106', 'FOODS_1_111', 'FOODS_1_115', 'FOODS_1_128', 'FOODS_1_131', 'FOODS_1_137', 'FOODS_1_138', 'FOODS_1_168', 'FOODS_1_173', 'FOODS_1_189', 'FOODS_1_196', 'FOODS_1_200', 'FOODS_2_017', 'FOODS_2_019', 'FOODS_2_044', 'FOODS_2_047', 'FOODS_2_056']\n",
      "\n",
      "Unique counts -> sentiment: 8381 inventory: 200\n",
      "Exact intersection size: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(r\"D:\\CAPSTONE_FINAL\\data\")\n",
    "sent = pd.read_csv(DATA / \"item_review_sentiment_vader.csv\")\n",
    "inv  = pd.read_csv(DATA / \"item_inventory_score.csv\")\n",
    "\n",
    "print(\"sent shape:\", sent.shape)\n",
    "print(\"inv  shape:\", inv.shape)\n",
    "print(\"\\nDTypes:\")\n",
    "print(sent.dtypes)\n",
    "print(inv.dtypes)\n",
    "\n",
    "print(\"\\nSample sentiment item_id (first 20):\")\n",
    "print(sent[\"item_id\"].astype(str).head(20).tolist())\n",
    "\n",
    "print(\"\\nSample inventory item_id (first 20):\")\n",
    "print(inv[\"item_id\"].astype(str).head(20).tolist())\n",
    "\n",
    "# intersection size (fast)\n",
    "set_sent = set(sent[\"item_id\"].astype(str).unique())\n",
    "set_inv  = set(inv[\"item_id\"].astype(str).unique())\n",
    "print(\"\\nUnique counts -> sentiment:\", len(set_sent), \"inventory:\", len(set_inv))\n",
    "print(\"Exact intersection size:\", len(set_sent & set_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9bacc1b-7fea-4863-8106-f385cc5d4d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent item_id length summary:\n",
      "count    8381.0\n",
      "mean       10.0\n",
      "std         0.0\n",
      "min        10.0\n",
      "25%        10.0\n",
      "50%        10.0\n",
      "75%        10.0\n",
      "max        10.0\n",
      "Name: item_id, dtype: float64\n",
      "inv item_id length summary:\n",
      "count    200.000000\n",
      "mean      12.840000\n",
      "std        1.797374\n",
      "min       11.000000\n",
      "25%       11.000000\n",
      "50%       13.000000\n",
      "75%       15.000000\n",
      "max       15.000000\n",
      "Name: item_id, dtype: float64\n",
      "\n",
      "Longest sentiment item_ids (5):\n",
      "['B0002L5R78', 'B000BQ7GW8', 'B00007E7JU', 'B00004ZCJE', 'B0001FTVEK']\n",
      "\n",
      "Longest inventory item_ids (5):\n",
      "['HOUSEHOLD_1_014', 'HOUSEHOLD_1_015', 'HOUSEHOLD_1_038', 'HOUSEHOLD_1_094', 'HOUSEHOLD_1_096']\n"
     ]
    }
   ],
   "source": [
    "# show distribution of string lengths (helps spot prefixes/suffixes)\n",
    "sent_lengths = sent[\"item_id\"].astype(str).map(len)\n",
    "inv_lengths  = inv[\"item_id\"].astype(str).map(len)\n",
    "\n",
    "print(\"sent item_id length summary:\")\n",
    "print(sent_lengths.describe())\n",
    "print(\"inv item_id length summary:\")\n",
    "print(inv_lengths.describe())\n",
    "\n",
    "# show some long/short examples\n",
    "print(\"\\nLongest sentiment item_ids (5):\")\n",
    "print(sent.loc[sent_lengths.nlargest(5).index, \"item_id\"].tolist())\n",
    "print(\"\\nLongest inventory item_ids (5):\")\n",
    "print(inv.loc[inv_lengths.nlargest(5).index, \"item_id\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d585103-2e32-4790-88e1-537aa4ae19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples only in sentiment (30):\n",
      "0528881469\n",
      "0594451647\n",
      "0594481813\n",
      "0972683275\n",
      "1400501466\n",
      "1400501520\n",
      "1400501776\n",
      "1400532620\n",
      "1400532655\n",
      "140053271X\n",
      "1400532736\n",
      "1400599997\n",
      "1400698987\n",
      "1400699169\n",
      "1615527613\n",
      "3744295508\n",
      "3930992868\n",
      "3936710058\n",
      "6301977173\n",
      "7214047977\n",
      "7507825604\n",
      "7799813393\n",
      "8862935293\n",
      "8862936826\n",
      "8918010656\n",
      "9043413585\n",
      "9573212900\n",
      "9573212919\n",
      "9575871979\n",
      "9625993428\n",
      "\n",
      "Examples only in inventory (30):\n",
      "FOODS_1_029\n",
      "FOODS_1_050\n",
      "FOODS_1_077\n",
      "FOODS_1_106\n",
      "FOODS_1_111\n",
      "FOODS_1_115\n",
      "FOODS_1_128\n",
      "FOODS_1_131\n",
      "FOODS_1_137\n",
      "FOODS_1_138\n",
      "FOODS_1_168\n",
      "FOODS_1_173\n",
      "FOODS_1_189\n",
      "FOODS_1_196\n",
      "FOODS_1_200\n",
      "FOODS_2_017\n",
      "FOODS_2_019\n",
      "FOODS_2_044\n",
      "FOODS_2_047\n",
      "FOODS_2_056\n",
      "FOODS_2_071\n",
      "FOODS_2_103\n",
      "FOODS_2_129\n",
      "FOODS_2_171\n",
      "FOODS_2_176\n",
      "FOODS_2_184\n",
      "FOODS_2_201\n",
      "FOODS_2_207\n",
      "FOODS_2_236\n",
      "FOODS_2_248\n"
     ]
    }
   ],
   "source": [
    "# show some item_ids present in sentiment but not in inventory\n",
    "only_sent = sorted(list(set_sent - set_inv))[:30]\n",
    "only_inv  = sorted(list(set_inv - set_sent))[:30]\n",
    "\n",
    "print(\"Examples only in sentiment (30):\")\n",
    "for x in only_sent:\n",
    "    print(x)\n",
    "print(\"\\nExamples only in inventory (30):\")\n",
    "for x in only_inv:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04733628-a140-467f-950a-79ec5c7513c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact intersection after basic strip+lower: 0\n",
      "Intersection after removing known suffixes: 0\n",
      "Intersection after first3 tokens: 0\n"
     ]
    }
   ],
   "source": [
    "def normalize_basic(srs):\n",
    "    s = srs.astype(str).str.strip().str.lower()\n",
    "    s = s.str.replace(r'\\r|\\n', ' ', regex=True)\n",
    "    return s\n",
    "\n",
    "sent[\"id_norm_basic\"] = normalize_basic(sent[\"item_id\"])\n",
    "inv[\"id_norm_basic\"]  = normalize_basic(inv[\"item_id\"])\n",
    "\n",
    "print(\"Exact intersection after basic strip+lower:\", \n",
    "      len(set(sent[\"id_norm_basic\"].unique()) & set(inv[\"id_norm_basic\"].unique())))\n",
    "\n",
    "# remove some known suffixes often present in these datasets\n",
    "suffixes = [\"_validation\", \"_train\", \"_test\", \"_validation_long\", \"_validation_1\"]\n",
    "def remove_suffixes(srs):\n",
    "    s = srs.copy()\n",
    "    for suf in suffixes:\n",
    "        s = s.str.replace(f\"{suf}$\", \"\", regex=True)\n",
    "    return s\n",
    "\n",
    "sent[\"id_norm_nosuf\"] = remove_suffixes(sent[\"id_norm_basic\"])\n",
    "inv[\"id_norm_nosuf\"]  = remove_suffixes(inv[\"id_norm_basic\"])\n",
    "\n",
    "print(\"Intersection after removing known suffixes:\", \n",
    "      len(set(sent[\"id_norm_nosuf\"].unique()) & set(inv[\"id_norm_nosuf\"].unique())))\n",
    "\n",
    "# try shortening by taking first 3 underscore-separated tokens (useful if inventory has shorter canonical ids)\n",
    "def take_first_tokens(srs, n=3):\n",
    "    return srs.str.split(\"\").map(lambda t: \"\".join(t[:n]) if len(t)>=n else \"_\".join(t))\n",
    "\n",
    "sent[\"id_first3\"] = take_first_tokens(sent[\"id_norm_nosuf\"], 3)\n",
    "inv[\"id_first3\"]  = take_first_tokens(inv[\"id_norm_nosuf\"], 3)\n",
    "print(\"Intersection after first3 tokens:\", \n",
    "      len(set(sent[\"id_first3\"].unique()) & set(inv[\"id_first3\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "805371e3-c5b4-4935-94af-e8dea864f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files with possible matches (sample scan): {'catalog.csv': ['item_id'], 'events.csv': ['item_id'], 'item_review_sentiment_vader.csv': ['item_id']}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA = Path(r\"D:\\CAPSTONE_FINAL\\data\")\n",
    "sent = pd.read_csv(DATA / \"item_review_sentiment_vader.csv\")\n",
    "sample_asins = list(sent[\"item_id\"].astype(str).unique())[:50]    # sample 50 unique ids\n",
    "\n",
    "def scan_csvs_for_ids(data_dir, ids_to_find, limit_files=20):\n",
    "    found = {}\n",
    "    for p in sorted(data_dir.glob(\"*.csv\")):\n",
    "        try:\n",
    "            df = pd.read_csv(p, nrows=2000, dtype=str)   # sample first 2k rows\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        cols = df.columns.tolist()\n",
    "        # check any column that looks like an item id col\n",
    "        for col in cols:\n",
    "            # if at least one sample id appears in this column, record it\n",
    "            if df[col].isin(ids_to_find).any():\n",
    "                found[p.name] = found.get(p.name, []) + [col]\n",
    "    return found\n",
    "\n",
    "found = scan_csvs_for_ids(DATA, set(sample_asins))\n",
    "print(\"Files with possible matches (sample scan):\", found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feef07ad-9129-44e2-aa9f-ee9290ff1daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- catalog.csv exists: True ---\n",
      "columns: ['item_id', 'title', 'category', 'price', 'cost', 'initial_inventory']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>cost</th>\n",
       "      <th>initial_inventory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0528881469</td>\n",
       "      <td>Item_0528881469</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>218.5430534813131</td>\n",
       "      <td>131.12583208878786</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0594451647</td>\n",
       "      <td>Item_0594451647</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>477.8214378844623</td>\n",
       "      <td>286.69286273067735</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0594481813</td>\n",
       "      <td>Item_0594481813</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>379.3972738151323</td>\n",
       "      <td>227.63836428907936</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0972683275</td>\n",
       "      <td>Item_0972683275</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>319.3963178886665</td>\n",
       "      <td>191.6377907331999</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400501466</td>\n",
       "      <td>Item_1400501466</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>120.20838819909643</td>\n",
       "      <td>72.12503291945785</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1400501520</td>\n",
       "      <td>Item_1400501520</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>120.1975341512912</td>\n",
       "      <td>72.11852049077471</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1400501776</td>\n",
       "      <td>Item_1400501776</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>76.13762547568976</td>\n",
       "      <td>45.682575285413854</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1400532620</td>\n",
       "      <td>Item_1400532620</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>439.7792655987208</td>\n",
       "      <td>263.8675593592325</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1400532655</td>\n",
       "      <td>Item_1400532655</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>320.50175528444396</td>\n",
       "      <td>192.30105317066636</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140053271X</td>\n",
       "      <td>Item_140053271X</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>368.63266000822045</td>\n",
       "      <td>221.17959600493228</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id            title     category               price  \\\n",
       "0  0528881469  Item_0528881469  Electronics   218.5430534813131   \n",
       "1  0594451647  Item_0594451647  Electronics   477.8214378844623   \n",
       "2  0594481813  Item_0594481813  Electronics   379.3972738151323   \n",
       "3  0972683275  Item_0972683275  Electronics   319.3963178886665   \n",
       "4  1400501466  Item_1400501466  Electronics  120.20838819909643   \n",
       "5  1400501520  Item_1400501520  Electronics   120.1975341512912   \n",
       "6  1400501776  Item_1400501776  Electronics   76.13762547568976   \n",
       "7  1400532620  Item_1400532620  Electronics   439.7792655987208   \n",
       "8  1400532655  Item_1400532655  Electronics  320.50175528444396   \n",
       "9  140053271X  Item_140053271X  Electronics  368.63266000822045   \n",
       "\n",
       "                 cost initial_inventory  \n",
       "0  131.12583208878786                94  \n",
       "1  286.69286273067735               420  \n",
       "2  227.63836428907936               392  \n",
       "3   191.6377907331999               189  \n",
       "4   72.12503291945785               226  \n",
       "5   72.11852049077471               271  \n",
       "6  45.682575285413854               464  \n",
       "7   263.8675593592325               141  \n",
       "8  192.30105317066636                71  \n",
       "9  221.17959600493228               221  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- events.csv exists: True ---\n",
      "columns: ['user_id', 'item_id', 'ts', 'event_type', 'qty', 'price']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>event_type</th>\n",
       "      <th>qty</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00472881KT6WR48K907X</td>\n",
       "      <td>B0000AZJZT</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "      <td>371.32372552015704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00472881KT6WR48K907X</td>\n",
       "      <td>B0000AZJZT</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1</td>\n",
       "      <td>371.32372552015704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01036691ZFOFCXBLP2D1</td>\n",
       "      <td>B00066IJPQ</td>\n",
       "      <td>2012-10-17</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "      <td>398.5185214039059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01036691ZFOFCXBLP2D1</td>\n",
       "      <td>B00066IJPQ</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1</td>\n",
       "      <td>398.5185214039059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01036691ZFOFCXBLP2D1</td>\n",
       "      <td>B000BUIP6K</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "      <td>294.2951595623623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A01036691ZFOFCXBLP2D1</td>\n",
       "      <td>B000BUIP6K</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1</td>\n",
       "      <td>294.2951595623623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0103849GBVWICKXD4T6</td>\n",
       "      <td>B000067RRX</td>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "      <td>452.66749522723745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0103849GBVWICKXD4T6</td>\n",
       "      <td>B000067RRX</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1</td>\n",
       "      <td>452.66749522723745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0191512Q2Z9IPUAE2RZ</td>\n",
       "      <td>B00030AXNQ</td>\n",
       "      <td>2013-07-08</td>\n",
       "      <td>view</td>\n",
       "      <td>1</td>\n",
       "      <td>77.87593336054456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0191512Q2Z9IPUAE2RZ</td>\n",
       "      <td>B00030AXNQ</td>\n",
       "      <td>2013-07-20</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1</td>\n",
       "      <td>77.87593336054456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id          ts event_type qty  \\\n",
       "0  A00472881KT6WR48K907X  B0000AZJZT  2013-02-05       view   1   \n",
       "1  A00472881KT6WR48K907X  B0000AZJZT  2013-02-18   purchase   1   \n",
       "2  A01036691ZFOFCXBLP2D1  B00066IJPQ  2012-10-17       view   1   \n",
       "3  A01036691ZFOFCXBLP2D1  B00066IJPQ  2012-11-12   purchase   1   \n",
       "4  A01036691ZFOFCXBLP2D1  B000BUIP6K  2013-12-30       view   1   \n",
       "5  A01036691ZFOFCXBLP2D1  B000BUIP6K  2014-01-21   purchase   1   \n",
       "6   A0103849GBVWICKXD4T6  B000067RRX  2013-02-08       view   1   \n",
       "7   A0103849GBVWICKXD4T6  B000067RRX  2013-03-01   purchase   1   \n",
       "8   A0191512Q2Z9IPUAE2RZ  B00030AXNQ  2013-07-08       view   1   \n",
       "9   A0191512Q2Z9IPUAE2RZ  B00030AXNQ  2013-07-20   purchase   1   \n",
       "\n",
       "                price  \n",
       "0  371.32372552015704  \n",
       "1  371.32372552015704  \n",
       "2   398.5185214039059  \n",
       "3   398.5185214039059  \n",
       "4   294.2951595623623  \n",
       "5   294.2951595623623  \n",
       "6  452.66749522723745  \n",
       "7  452.66749522723745  \n",
       "8   77.87593336054456  \n",
       "9   77.87593336054456  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA = Path(r\"D:\\CAPSTONE_FINAL\\data\")\n",
    "for fname in [\"catalog.csv\", \"events.csv\"]:\n",
    "    p = DATA / fname\n",
    "    print(\"\\n\\n---\", fname, \"exists:\", p.exists(), \"---\")\n",
    "    if p.exists():\n",
    "        df = pd.read_csv(p, nrows=20, dtype=str)\n",
    "        print(\"columns:\", df.columns.tolist())\n",
    "        display(df.head(10))\n",
    "    else:\n",
    "        print(\"File not found:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "322d886b-a104-44ca-8146-6d96227c2bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate mapping columns (col -> fraction that look like internal SKUs):\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "p = DATA / \"catalog.csv\"\n",
    "df = pd.read_csv(p, nrows=5000, dtype=str)   # sample first 5k rows\n",
    "def looks_like_internal_id(s):\n",
    "    if pd.isna(s): return False\n",
    "    # heuristic: contains underscore + a digit (adjust if inventory IDs are different)\n",
    "    return bool(re.search(r\"_\\d\", s))\n",
    "\n",
    "candidates = {}\n",
    "for col in df.columns:\n",
    "    colvals = df[col].dropna().astype(str)\n",
    "    if len(colvals)==0: continue\n",
    "    match_frac = colvals.map(looks_like_internal_id).mean()\n",
    "    if match_frac > 0.01:   # more than 1% look like internal ids\n",
    "        candidates[col] = match_frac\n",
    "\n",
    "print(\"Candidate mapping columns (col -> fraction that look like internal SKUs):\")\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83cd921f-86e0-4ce3-9093-9b99a6412529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 8381  Matched: 1527  Unmatched: 6854\n",
      "Match type counts:\n",
      "match_type\n",
      "token_exact_multi_choice    1477\n",
      "token_exact_unique            35\n",
      "suffix_3_unique               14\n",
      "suffix_3_multi_choice          1\n",
      "Name: count, dtype: int64\n",
      "Saved -> D:\\CAPSTONE_FINAL\\data/merged_numeric_match_sent_inv.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>review_count</th>\n",
       "      <th>avg_pos_prob</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>cost</th>\n",
       "      <th>initial_inventory</th>\n",
       "      <th>matched_inventory_id</th>\n",
       "      <th>match_type</th>\n",
       "      <th>match_token</th>\n",
       "      <th>match_score</th>\n",
       "      <th>match_flag</th>\n",
       "      <th>item_id_inv</th>\n",
       "      <th>pred_next_28_inv</th>\n",
       "      <th>initial_inventory_inv</th>\n",
       "      <th>inventory_score_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00005T3G0</td>\n",
       "      <td>712</td>\n",
       "      <td>0.8007078651685388</td>\n",
       "      <td>0.8595505617977528</td>\n",
       "      <td>0.054775280898876406</td>\n",
       "      <td>4.643258426966292</td>\n",
       "      <td>Item_B00005T3G0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>474.91992010104525</td>\n",
       "      <td>284.95195206062715</td>\n",
       "      <td>174</td>\n",
       "      <td>FOODS_3_041</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>3</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_3_041</td>\n",
       "      <td>29.086063802944718</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29086063802653855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00007M1TZ</td>\n",
       "      <td>677</td>\n",
       "      <td>0.7725706794682412</td>\n",
       "      <td>0.7976366322008862</td>\n",
       "      <td>0.11669128508124077</td>\n",
       "      <td>4.140324963072378</td>\n",
       "      <td>Item_B00007M1TZ</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>140.9070507811205</td>\n",
       "      <td>84.5442304686723</td>\n",
       "      <td>183</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>3.531231454686384</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312314546510716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B0000BZL1P</td>\n",
       "      <td>601</td>\n",
       "      <td>0.820068552412645</td>\n",
       "      <td>0.8668885191347754</td>\n",
       "      <td>0.059900166389351084</td>\n",
       "      <td>4.80865224625624</td>\n",
       "      <td>Item_B0000BZL1P</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>276.1840591835587</td>\n",
       "      <td>165.71043551013523</td>\n",
       "      <td>164</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>3.531231454686384</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312314546510716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B0007MXZB2</td>\n",
       "      <td>589</td>\n",
       "      <td>0.7741140916808148</td>\n",
       "      <td>0.7945670628183361</td>\n",
       "      <td>0.11884550084889643</td>\n",
       "      <td>3.767402376910017</td>\n",
       "      <td>Item_B0007MXZB2</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>212.69308449333047</td>\n",
       "      <td>127.61585069599828</td>\n",
       "      <td>239</td>\n",
       "      <td>FOODS_2_265</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_2_265</td>\n",
       "      <td>7.986474159441755</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.07986474159361891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B00004T8R2</td>\n",
       "      <td>552</td>\n",
       "      <td>0.8274965579710146</td>\n",
       "      <td>0.8641304347826086</td>\n",
       "      <td>0.07065217391304347</td>\n",
       "      <td>4.378623188405797</td>\n",
       "      <td>Item_B00004T8R2</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>68.32796104353656</td>\n",
       "      <td>40.996776626121935</td>\n",
       "      <td>387</td>\n",
       "      <td>FOODS_2_265</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_2_265</td>\n",
       "      <td>7.986474159441755</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.07986474159361891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>B00006JN3G</td>\n",
       "      <td>425</td>\n",
       "      <td>0.7982185882352935</td>\n",
       "      <td>0.8494117647058823</td>\n",
       "      <td>0.06352941176470588</td>\n",
       "      <td>4.425882352941176</td>\n",
       "      <td>Item_B00006JN3G</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>244.4345973248882</td>\n",
       "      <td>146.6607583949329</td>\n",
       "      <td>463</td>\n",
       "      <td>FOODS_3_041</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>3</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_3_041</td>\n",
       "      <td>29.086063802944718</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29086063802653855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>B00081A2KY</td>\n",
       "      <td>418</td>\n",
       "      <td>0.7276991626794264</td>\n",
       "      <td>0.7679425837320574</td>\n",
       "      <td>0.13157894736842105</td>\n",
       "      <td>4.492822966507177</td>\n",
       "      <td>Item_B00081A2KY</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>231.1368599705639</td>\n",
       "      <td>138.68211598233833</td>\n",
       "      <td>452</td>\n",
       "      <td>FOODS_2_265</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_2_265</td>\n",
       "      <td>7.986474159441755</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.07986474159361891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>B00029U1DK</td>\n",
       "      <td>410</td>\n",
       "      <td>0.7269604878048779</td>\n",
       "      <td>0.7560975609756098</td>\n",
       "      <td>0.11463414634146342</td>\n",
       "      <td>4.5512195121951216</td>\n",
       "      <td>Item_B00029U1DK</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>402.5613020221705</td>\n",
       "      <td>241.53678121330228</td>\n",
       "      <td>90</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>3.531231454686384</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312314546510716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>B000C1Z0HA</td>\n",
       "      <td>374</td>\n",
       "      <td>0.7733991978609626</td>\n",
       "      <td>0.7941176470588235</td>\n",
       "      <td>0.12299465240641712</td>\n",
       "      <td>4.278074866310161</td>\n",
       "      <td>Item_B000C1Z0HA</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>350.60875363065196</td>\n",
       "      <td>210.36525217839116</td>\n",
       "      <td>261</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_1_077</td>\n",
       "      <td>3.531231454686384</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312314546510716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>B000089GN3</td>\n",
       "      <td>333</td>\n",
       "      <td>0.896427027027027</td>\n",
       "      <td>0.9279279279279279</td>\n",
       "      <td>0.04504504504504504</td>\n",
       "      <td>4.558558558558558</td>\n",
       "      <td>Item_B000089GN3</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>81.33851667308258</td>\n",
       "      <td>48.80311000384955</td>\n",
       "      <td>76</td>\n",
       "      <td>FOODS_3_041</td>\n",
       "      <td>token_exact_multi_choice</td>\n",
       "      <td>3</td>\n",
       "      <td>0.81</td>\n",
       "      <td>True</td>\n",
       "      <td>FOODS_3_041</td>\n",
       "      <td>29.086063802944718</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.29086063802653855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id review_count        avg_pos_prob           pos_ratio  \\\n",
       "6   B00005T3G0          712  0.8007078651685388  0.8595505617977528   \n",
       "8   B00007M1TZ          677  0.7725706794682412  0.7976366322008862   \n",
       "11  B0000BZL1P          601   0.820068552412645  0.8668885191347754   \n",
       "12  B0007MXZB2          589  0.7741140916808148  0.7945670628183361   \n",
       "18  B00004T8R2          552  0.8274965579710146  0.8641304347826086   \n",
       "31  B00006JN3G          425  0.7982185882352935  0.8494117647058823   \n",
       "33  B00081A2KY          418  0.7276991626794264  0.7679425837320574   \n",
       "35  B00029U1DK          410  0.7269604878048779  0.7560975609756098   \n",
       "40  B000C1Z0HA          374  0.7733991978609626  0.7941176470588235   \n",
       "47  B000089GN3          333   0.896427027027027  0.9279279279279279   \n",
       "\n",
       "               neg_ratio          avg_rating            title     category  \\\n",
       "6   0.054775280898876406   4.643258426966292  Item_B00005T3G0  Electronics   \n",
       "8    0.11669128508124077   4.140324963072378  Item_B00007M1TZ  Electronics   \n",
       "11  0.059900166389351084    4.80865224625624  Item_B0000BZL1P  Electronics   \n",
       "12   0.11884550084889643   3.767402376910017  Item_B0007MXZB2  Electronics   \n",
       "18   0.07065217391304347   4.378623188405797  Item_B00004T8R2  Electronics   \n",
       "31   0.06352941176470588   4.425882352941176  Item_B00006JN3G  Electronics   \n",
       "33   0.13157894736842105   4.492822966507177  Item_B00081A2KY  Electronics   \n",
       "35   0.11463414634146342  4.5512195121951216  Item_B00029U1DK  Electronics   \n",
       "40   0.12299465240641712   4.278074866310161  Item_B000C1Z0HA  Electronics   \n",
       "47   0.04504504504504504   4.558558558558558  Item_B000089GN3  Electronics   \n",
       "\n",
       "                 price                cost initial_inventory  \\\n",
       "6   474.91992010104525  284.95195206062715               174   \n",
       "8    140.9070507811205    84.5442304686723               183   \n",
       "11   276.1840591835587  165.71043551013523               164   \n",
       "12  212.69308449333047  127.61585069599828               239   \n",
       "18   68.32796104353656  40.996776626121935               387   \n",
       "31   244.4345973248882   146.6607583949329               463   \n",
       "33   231.1368599705639  138.68211598233833               452   \n",
       "35   402.5613020221705  241.53678121330228                90   \n",
       "40  350.60875363065196  210.36525217839116               261   \n",
       "47   81.33851667308258   48.80311000384955                76   \n",
       "\n",
       "   matched_inventory_id                match_type match_token  match_score  \\\n",
       "6           FOODS_3_041  token_exact_multi_choice           3         0.81   \n",
       "8           FOODS_1_077  token_exact_multi_choice           1         0.81   \n",
       "11          FOODS_1_077  token_exact_multi_choice           1         0.81   \n",
       "12          FOODS_2_265  token_exact_multi_choice           2         0.81   \n",
       "18          FOODS_2_265  token_exact_multi_choice           2         0.81   \n",
       "31          FOODS_3_041  token_exact_multi_choice           3         0.81   \n",
       "33          FOODS_2_265  token_exact_multi_choice           2         0.81   \n",
       "35          FOODS_1_077  token_exact_multi_choice           1         0.81   \n",
       "40          FOODS_1_077  token_exact_multi_choice           1         0.81   \n",
       "47          FOODS_3_041  token_exact_multi_choice           3         0.81   \n",
       "\n",
       "    match_flag  item_id_inv    pred_next_28_inv initial_inventory_inv  \\\n",
       "6         True  FOODS_3_041  29.086063802944718                 100.0   \n",
       "8         True  FOODS_1_077   3.531231454686384                 100.0   \n",
       "11        True  FOODS_1_077   3.531231454686384                 100.0   \n",
       "12        True  FOODS_2_265   7.986474159441755                 100.0   \n",
       "18        True  FOODS_2_265   7.986474159441755                 100.0   \n",
       "31        True  FOODS_3_041  29.086063802944718                 100.0   \n",
       "33        True  FOODS_2_265   7.986474159441755                 100.0   \n",
       "35        True  FOODS_1_077   3.531231454686384                 100.0   \n",
       "40        True  FOODS_1_077   3.531231454686384                 100.0   \n",
       "47        True  FOODS_3_041  29.086063802944718                 100.0   \n",
       "\n",
       "     inventory_score_inv  \n",
       "6    0.29086063802653855  \n",
       "8   0.035312314546510716  \n",
       "11  0.035312314546510716  \n",
       "12   0.07986474159361891  \n",
       "18   0.07986474159361891  \n",
       "31   0.29086063802653855  \n",
       "33   0.07986474159361891  \n",
       "35  0.035312314546510716  \n",
       "40  0.035312314546510716  \n",
       "47   0.29086063802653855  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>review_count</th>\n",
       "      <th>avg_pos_prob</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>cost</th>\n",
       "      <th>initial_inventory</th>\n",
       "      <th>matched_inventory_id</th>\n",
       "      <th>match_type</th>\n",
       "      <th>match_token</th>\n",
       "      <th>match_score</th>\n",
       "      <th>match_flag</th>\n",
       "      <th>item_id_inv</th>\n",
       "      <th>pred_next_28_inv</th>\n",
       "      <th>initial_inventory_inv</th>\n",
       "      <th>inventory_score_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0002L5R78</td>\n",
       "      <td>2598</td>\n",
       "      <td>0.7688803117782913</td>\n",
       "      <td>0.8144726712856043</td>\n",
       "      <td>0.08352578906851424</td>\n",
       "      <td>4.599692070823711</td>\n",
       "      <td>Item_B0002L5R78</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>161.87219807598785</td>\n",
       "      <td>97.1233188455927</td>\n",
       "      <td>302</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>1388</td>\n",
       "      <td>0.7554894812680115</td>\n",
       "      <td>0.7982708933717579</td>\n",
       "      <td>0.07276657060518732</td>\n",
       "      <td>4.695965417867435</td>\n",
       "      <td>Item_B000BQ7GW8</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>360.77689057398635</td>\n",
       "      <td>216.4661343443918</td>\n",
       "      <td>186</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00007E7JU</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.865585043069695</td>\n",
       "      <td>0.9075959279561472</td>\n",
       "      <td>0.052466718872357085</td>\n",
       "      <td>4.5880971025841815</td>\n",
       "      <td>Item_B00007E7JU</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>289.5893070238477</td>\n",
       "      <td>173.75358421430863</td>\n",
       "      <td>267</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00004ZCJE</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.7537034976152621</td>\n",
       "      <td>0.7917329093799682</td>\n",
       "      <td>0.09697933227344992</td>\n",
       "      <td>4.282193958664547</td>\n",
       "      <td>Item_B00004ZCJE</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>350.40098233446224</td>\n",
       "      <td>210.24058940067735</td>\n",
       "      <td>482</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0001FTVEK</td>\n",
       "      <td>950</td>\n",
       "      <td>0.7879298947368415</td>\n",
       "      <td>0.8010526315789473</td>\n",
       "      <td>0.13263157894736843</td>\n",
       "      <td>3.8957894736842107</td>\n",
       "      <td>Item_B0001FTVEK</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>231.08281668469027</td>\n",
       "      <td>138.64969001081417</td>\n",
       "      <td>274</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B000A6PPOK</td>\n",
       "      <td>809</td>\n",
       "      <td>0.7618190358467255</td>\n",
       "      <td>0.7787391841779975</td>\n",
       "      <td>0.16069221260815822</td>\n",
       "      <td>4.016069221260816</td>\n",
       "      <td>Item_B000A6PPOK</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>137.13071440795736</td>\n",
       "      <td>82.27842864477441</td>\n",
       "      <td>454</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B000CKVOOY</td>\n",
       "      <td>703</td>\n",
       "      <td>0.8526633712660026</td>\n",
       "      <td>0.9160739687055477</td>\n",
       "      <td>0.02418207681365576</td>\n",
       "      <td>4.695590327169275</td>\n",
       "      <td>Item_B000CKVOOY</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>288.44403148319276</td>\n",
       "      <td>173.06641888991564</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00017LSPI</td>\n",
       "      <td>629</td>\n",
       "      <td>0.798560651828299</td>\n",
       "      <td>0.8441971383147854</td>\n",
       "      <td>0.07472178060413355</td>\n",
       "      <td>4.613672496025437</td>\n",
       "      <td>Item_B00017LSPI</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>408.16687421457607</td>\n",
       "      <td>244.90012452874564</td>\n",
       "      <td>476</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B00009R6TA</td>\n",
       "      <td>609</td>\n",
       "      <td>0.847428981937603</td>\n",
       "      <td>0.8834154351395731</td>\n",
       "      <td>0.047619047619047616</td>\n",
       "      <td>4.466338259441708</td>\n",
       "      <td>Item_B00009R6TA</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>276.38777785092634</td>\n",
       "      <td>165.8326667105558</td>\n",
       "      <td>234</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B00007EDZG</td>\n",
       "      <td>586</td>\n",
       "      <td>0.7628065699658703</td>\n",
       "      <td>0.7935153583617748</td>\n",
       "      <td>0.08020477815699659</td>\n",
       "      <td>4.445392491467577</td>\n",
       "      <td>Item_B00007EDZG</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>432.777226028512</td>\n",
       "      <td>259.6663356171072</td>\n",
       "      <td>116</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id review_count        avg_pos_prob           pos_ratio  \\\n",
       "0   B0002L5R78         2598  0.7688803117782913  0.8144726712856043   \n",
       "1   B000BQ7GW8         1388  0.7554894812680115  0.7982708933717579   \n",
       "2   B00007E7JU         1277   0.865585043069695  0.9075959279561472   \n",
       "3   B00004ZCJE         1258  0.7537034976152621  0.7917329093799682   \n",
       "4   B0001FTVEK          950  0.7879298947368415  0.8010526315789473   \n",
       "5   B000A6PPOK          809  0.7618190358467255  0.7787391841779975   \n",
       "7   B000CKVOOY          703  0.8526633712660026  0.9160739687055477   \n",
       "9   B00017LSPI          629   0.798560651828299  0.8441971383147854   \n",
       "10  B00009R6TA          609   0.847428981937603  0.8834154351395731   \n",
       "13  B00007EDZG          586  0.7628065699658703  0.7935153583617748   \n",
       "\n",
       "               neg_ratio          avg_rating            title     category  \\\n",
       "0    0.08352578906851424   4.599692070823711  Item_B0002L5R78  Electronics   \n",
       "1    0.07276657060518732   4.695965417867435  Item_B000BQ7GW8  Electronics   \n",
       "2   0.052466718872357085  4.5880971025841815  Item_B00007E7JU  Electronics   \n",
       "3    0.09697933227344992   4.282193958664547  Item_B00004ZCJE  Electronics   \n",
       "4    0.13263157894736843  3.8957894736842107  Item_B0001FTVEK  Electronics   \n",
       "5    0.16069221260815822   4.016069221260816  Item_B000A6PPOK  Electronics   \n",
       "7    0.02418207681365576   4.695590327169275  Item_B000CKVOOY  Electronics   \n",
       "9    0.07472178060413355   4.613672496025437  Item_B00017LSPI  Electronics   \n",
       "10  0.047619047619047616   4.466338259441708  Item_B00009R6TA  Electronics   \n",
       "13   0.08020477815699659   4.445392491467577  Item_B00007EDZG  Electronics   \n",
       "\n",
       "                 price                cost initial_inventory  \\\n",
       "0   161.87219807598785    97.1233188455927               302   \n",
       "1   360.77689057398635   216.4661343443918               186   \n",
       "2    289.5893070238477  173.75358421430863               267   \n",
       "3   350.40098233446224  210.24058940067735               482   \n",
       "4   231.08281668469027  138.64969001081417               274   \n",
       "5   137.13071440795736   82.27842864477441               454   \n",
       "7   288.44403148319276  173.06641888991564                55   \n",
       "9   408.16687421457607  244.90012452874564               476   \n",
       "10  276.38777785092634   165.8326667105558               234   \n",
       "13    432.777226028512   259.6663356171072               116   \n",
       "\n",
       "   matched_inventory_id match_type match_token  match_score  match_flag  \\\n",
       "0                  None       None        None          0.0       False   \n",
       "1                  None       None        None          0.0       False   \n",
       "2                  None       None        None          0.0       False   \n",
       "3                  None       None        None          0.0       False   \n",
       "4                  None       None        None          0.0       False   \n",
       "5                  None       None        None          0.0       False   \n",
       "7                  None       None        None          0.0       False   \n",
       "9                  None       None        None          0.0       False   \n",
       "10                 None       None        None          0.0       False   \n",
       "13                 None       None        None          0.0       False   \n",
       "\n",
       "   item_id_inv pred_next_28_inv initial_inventory_inv inventory_score_inv  \n",
       "0          NaN              NaN                   NaN                 NaN  \n",
       "1          NaN              NaN                   NaN                 NaN  \n",
       "2          NaN              NaN                   NaN                 NaN  \n",
       "3          NaN              NaN                   NaN                 NaN  \n",
       "4          NaN              NaN                   NaN                 NaN  \n",
       "5          NaN              NaN                   NaN                 NaN  \n",
       "7          NaN              NaN                   NaN                 NaN  \n",
       "9          NaN              NaN                   NaN                 NaN  \n",
       "10         NaN              NaN                   NaN                 NaN  \n",
       "13         NaN              NaN                   NaN                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numeric-token matching (3rd way)\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA = r\"D:\\CAPSTONE_FINAL\\data\"\n",
    "\n",
    "# load inputs (force as strings)\n",
    "sent = pd.read_csv(f\"{DATA}/item_review_sentiment_vader.csv\", dtype=str)\n",
    "catalog = pd.read_csv(f\"{DATA}/catalog.csv\", dtype=str)\n",
    "inv = pd.read_csv(f\"{DATA}/item_inventory_score.csv\", dtype=str)\n",
    "\n",
    "# normalize column names if necessary\n",
    "# sent item_id column name might be 'item_id' or 'ext_item_id' depending on prev steps\n",
    "if \"item_id\" not in sent.columns and \"ext_item_id\" in sent.columns:\n",
    "    sent = sent.rename(columns={\"ext_item_id\":\"item_id\"})\n",
    "\n",
    "# drop rows without item_id\n",
    "sent = sent.dropna(subset=[\"item_id\"])\n",
    "catalog = catalog.dropna(subset=[\"item_id\"])\n",
    "inv = inv.dropna(subset=[\"item_id\"])\n",
    "\n",
    "# helper to extract numeric tokens (all digit runs) from a string\n",
    "def numeric_tokens(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s)\n",
    "    toks = re.findall(r\"\\d+\", s)\n",
    "    return toks\n",
    "\n",
    "# build lookup maps for inventory: token -> set of inventory ids containing that token\n",
    "inv_token_map = defaultdict(set)\n",
    "inv_tokens_by_id = {}\n",
    "for iid in inv[\"item_id\"].tolist():\n",
    "    toks = numeric_tokens(iid)\n",
    "    inv_tokens_by_id[iid] = toks\n",
    "    for t in toks:\n",
    "        inv_token_map[t].add(iid)\n",
    "\n",
    "# same for catalog (we will merge sentiment -> catalog first)\n",
    "catalog_tokens_by_id = {}\n",
    "for cid in catalog[\"item_id\"].tolist():\n",
    "    catalog_tokens_by_id[cid] = numeric_tokens(cid)\n",
    "\n",
    "# merge sentiment with catalog on item_id (these are catalog external ids)\n",
    "merged = sent.merge(catalog, on=\"item_id\", how=\"left\", suffixes=(\"_sent\",\"_cat\"))\n",
    "\n",
    "# prepare result columns\n",
    "merged[\"matched_inventory_id\"] = None\n",
    "merged[\"match_type\"] = None\n",
    "merged[\"match_token\"] = None\n",
    "merged[\"match_score\"] = 0.0  # heuristic score to sort confidence\n",
    "\n",
    "# 1) First pass: exact numeric-token overlap (highest confidence)\n",
    "for idx, row in merged.iterrows():\n",
    "    ext_id = row[\"item_id\"]\n",
    "    toks = numeric_tokens(ext_id)\n",
    "    found = False\n",
    "    # try tokens from longest to shortest (long tokens are more specific)\n",
    "    toks_sorted = sorted(toks, key=lambda x: -len(x))\n",
    "    for t in toks_sorted:\n",
    "        candidates = inv_token_map.get(t, set())\n",
    "        if len(candidates) == 1:\n",
    "            # unique match\n",
    "            inv_id = next(iter(candidates))\n",
    "            merged.at[idx, \"matched_inventory_id\"] = inv_id\n",
    "            merged.at[idx, \"match_type\"] = \"token_exact_unique\"\n",
    "            merged.at[idx, \"match_token\"] = t\n",
    "            merged.at[idx, \"match_score\"] = 1.0 + len(t)/100.0\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        # try if any token has multiple candidates -> store best later\n",
    "        for t in toks_sorted:\n",
    "            candidates = inv_token_map.get(t, set())\n",
    "            if len(candidates) >= 1:\n",
    "                # tentatively pick the candidate with shortest full inventory id difference (heuristic)\n",
    "                # compute minimal string distance by comparing lengths (cheap)\n",
    "                best = None\n",
    "                best_len_diff = None\n",
    "                for cand in candidates:\n",
    "                    d = abs(len(cand) - len(ext_id))\n",
    "                    if best is None or d < best_len_diff:\n",
    "                        best = cand\n",
    "                        best_len_diff = d\n",
    "                if best is not None:\n",
    "                    merged.at[idx, \"matched_inventory_id\"] = best\n",
    "                    merged.at[idx, \"match_type\"] = \"token_exact_multi_choice\"\n",
    "                    merged.at[idx, \"match_token\"] = t\n",
    "                    merged.at[idx, \"match_score\"] = 0.8 + len(t)/100.0\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "# 2) Second pass: match on longest common numeric suffix (last 3-4 digits)\n",
    "for idx, row in merged[merged[\"matched_inventory_id\"].isna()].iterrows():\n",
    "    ext_id = row[\"item_id\"]\n",
    "    s = str(ext_id)\n",
    "    # try suffix lengths 4,3,2 (adjust as needed)\n",
    "    matched = False\n",
    "    for L in (4,3,2):\n",
    "        if len(s) >= L:\n",
    "            suf = s[-L:]\n",
    "            candidates = inv_token_map.get(suf, set())\n",
    "            if len(candidates) == 1:\n",
    "                inv_id = next(iter(candidates))\n",
    "                merged.at[idx, \"matched_inventory_id\"] = inv_id\n",
    "                merged.at[idx, \"match_type\"] = f\"suffix_{L}_unique\"\n",
    "                merged.at[idx, \"match_token\"] = suf\n",
    "                merged.at[idx, \"match_score\"] = 0.7 + L/100.0\n",
    "                matched = True\n",
    "                break\n",
    "            elif len(candidates) > 1:\n",
    "                # pick candidate with closest numeric token length\n",
    "                best = None\n",
    "                best_diff = None\n",
    "                for cand in candidates:\n",
    "                    cand_toks = inv_tokens_by_id.get(cand, [])\n",
    "                    # pick the token equal to suf (there may be multiple)\n",
    "                    for ct in cand_toks:\n",
    "                        if ct.endswith(suf):\n",
    "                            d = abs(len(ct)-len(suf))\n",
    "                            if best is None or d < best_diff:\n",
    "                                best = cand\n",
    "                                best_diff = d\n",
    "                if best is not None:\n",
    "                    merged.at[idx, \"matched_inventory_id\"] = best\n",
    "                    merged.at[idx, \"match_type\"] = f\"suffix_{L}_multi_choice\"\n",
    "                    merged.at[idx, \"match_token\"] = suf\n",
    "                    merged.at[idx, \"match_score\"] = 0.6 + L/100.0\n",
    "                    matched = True\n",
    "                    break\n",
    "    if matched:\n",
    "        continue\n",
    "\n",
    "# 3) Third pass: try matching by any numeric token equality (if still unmatched)\n",
    "for idx, row in merged[merged[\"matched_inventory_id\"].isna()].iterrows():\n",
    "    ext_id = row[\"item_id\"]\n",
    "    toks = numeric_tokens(ext_id)\n",
    "    if not toks:\n",
    "        continue\n",
    "    # pick the longest token that exists in inv_token_map\n",
    "    toks_sorted = sorted(toks, key=lambda x: -len(x))\n",
    "    for t in toks_sorted:\n",
    "        if t in inv_token_map and len(inv_token_map[t]) >= 1:\n",
    "            # choose first candidate deterministically\n",
    "            inv_id = sorted(list(inv_token_map[t]))[0]\n",
    "            merged.at[idx, \"matched_inventory_id\"] = inv_id\n",
    "            merged.at[idx, \"match_type\"] = \"token_first_fallback\"\n",
    "            merged.at[idx, \"match_token\"] = t\n",
    "            merged.at[idx, \"match_score\"] = 0.5 + len(t)/100.0\n",
    "            break\n",
    "\n",
    "# 4) Final: mark unmatched\n",
    "merged[\"matched_inventory_id\"] = merged[\"matched_inventory_id\"].astype(object)\n",
    "merged[\"match_flag\"] = merged[\"matched_inventory_id\"].notna()\n",
    "\n",
    "# quick summary\n",
    "total = len(merged)\n",
    "matched = merged[\"match_flag\"].sum()\n",
    "print(f\"Total rows: {total}  Matched: {matched}  Unmatched: {total-matched}\")\n",
    "print(\"Match type counts:\")\n",
    "print(merged[\"match_type\"].value_counts(dropna=True))\n",
    "\n",
    "# merge the matched inventory metadata back (initial_inventory, inventory_score) where available\n",
    "merged_final = merged.merge(inv.add_suffix(\"_inv\"), left_on=\"matched_inventory_id\", right_on=\"item_id_inv\", how=\"left\")\n",
    "\n",
    "# save result\n",
    "out_path = f\"{DATA}/merged_numeric_match_sent_inv.csv\"\n",
    "merged_final.to_csv(out_path, index=False)\n",
    "print(\"Saved ->\", out_path)\n",
    "\n",
    "# show sample of matches & unmatched\n",
    "display(merged_final.loc[merged_final[\"match_flag\"]==True].head(10))\n",
    "display(merged_final.loc[merged_final[\"match_flag\"]==False].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a63e868d-f86a-45e3-9f5f-37b61f65b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned dataset saved -> D:\\CAPSTONE_FINAL\\data\\final_merged_inventory_sentiment.csv\n",
      "Shape: (1527, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_pos_prob</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>predicted_sales_next_28_days</th>\n",
       "      <th>initial_inventory</th>\n",
       "      <th>inventory_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00005T3G0</td>\n",
       "      <td>Item_B00005T3G0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.800708</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.054775</td>\n",
       "      <td>4.643258</td>\n",
       "      <td>29.086064</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.290861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00007M1TZ</td>\n",
       "      <td>Item_B00007M1TZ</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.772571</td>\n",
       "      <td>0.797637</td>\n",
       "      <td>0.116691</td>\n",
       "      <td>4.140325</td>\n",
       "      <td>3.531231</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B0000BZL1P</td>\n",
       "      <td>Item_B0000BZL1P</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.820069</td>\n",
       "      <td>0.866889</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>4.808652</td>\n",
       "      <td>3.531231</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B0007MXZB2</td>\n",
       "      <td>Item_B0007MXZB2</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.774114</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.118846</td>\n",
       "      <td>3.767402</td>\n",
       "      <td>7.986474</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.079865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B00004T8R2</td>\n",
       "      <td>Item_B00004T8R2</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.827497</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>4.378623</td>\n",
       "      <td>7.986474</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.079865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>B00006JN3G</td>\n",
       "      <td>Item_B00006JN3G</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.798219</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.063529</td>\n",
       "      <td>4.425882</td>\n",
       "      <td>29.086064</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.290861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>B00081A2KY</td>\n",
       "      <td>Item_B00081A2KY</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.727699</td>\n",
       "      <td>0.767943</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>4.492823</td>\n",
       "      <td>7.986474</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.079865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>B00029U1DK</td>\n",
       "      <td>Item_B00029U1DK</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.726960</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.114634</td>\n",
       "      <td>4.551220</td>\n",
       "      <td>3.531231</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>B000C1Z0HA</td>\n",
       "      <td>Item_B000C1Z0HA</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.773399</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>4.278075</td>\n",
       "      <td>3.531231</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.035312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>B000089GN3</td>\n",
       "      <td>Item_B000089GN3</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0.896427</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>4.558559</td>\n",
       "      <td>29.086064</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.290861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id            title     category  avg_pos_prob  pos_ratio  \\\n",
       "6   B00005T3G0  Item_B00005T3G0  Electronics      0.800708   0.859551   \n",
       "8   B00007M1TZ  Item_B00007M1TZ  Electronics      0.772571   0.797637   \n",
       "11  B0000BZL1P  Item_B0000BZL1P  Electronics      0.820069   0.866889   \n",
       "12  B0007MXZB2  Item_B0007MXZB2  Electronics      0.774114   0.794567   \n",
       "18  B00004T8R2  Item_B00004T8R2  Electronics      0.827497   0.864130   \n",
       "31  B00006JN3G  Item_B00006JN3G  Electronics      0.798219   0.849412   \n",
       "33  B00081A2KY  Item_B00081A2KY  Electronics      0.727699   0.767943   \n",
       "35  B00029U1DK  Item_B00029U1DK  Electronics      0.726960   0.756098   \n",
       "40  B000C1Z0HA  Item_B000C1Z0HA  Electronics      0.773399   0.794118   \n",
       "47  B000089GN3  Item_B000089GN3  Electronics      0.896427   0.927928   \n",
       "\n",
       "    neg_ratio  avg_rating  predicted_sales_next_28_days  initial_inventory  \\\n",
       "6    0.054775    4.643258                     29.086064              100.0   \n",
       "8    0.116691    4.140325                      3.531231              100.0   \n",
       "11   0.059900    4.808652                      3.531231              100.0   \n",
       "12   0.118846    3.767402                      7.986474              100.0   \n",
       "18   0.070652    4.378623                      7.986474              100.0   \n",
       "31   0.063529    4.425882                     29.086064              100.0   \n",
       "33   0.131579    4.492823                      7.986474              100.0   \n",
       "35   0.114634    4.551220                      3.531231              100.0   \n",
       "40   0.122995    4.278075                      3.531231              100.0   \n",
       "47   0.045045    4.558559                     29.086064              100.0   \n",
       "\n",
       "    inventory_score  \n",
       "6          0.290861  \n",
       "8          0.035312  \n",
       "11         0.035312  \n",
       "12         0.079865  \n",
       "18         0.079865  \n",
       "31         0.290861  \n",
       "33         0.079865  \n",
       "35         0.035312  \n",
       "40         0.035312  \n",
       "47         0.290861  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cleanup and saving to run next\n",
    "import pandas as pd\n",
    "\n",
    "merged = pd.read_csv(r\"D:\\CAPSTONE_FINAL\\data\\merged_numeric_match_sent_inv.csv\")\n",
    "\n",
    "# keep only matched items\n",
    "matched_df = merged[merged[\"match_flag\"] == True].copy()\n",
    "\n",
    "# pick only meaningful columns for analysis\n",
    "final_df = matched_df[[\n",
    "    \"item_id\", \"title\", \"category\", \"avg_pos_prob\", \"pos_ratio\", \"neg_ratio\",\n",
    "    \"avg_rating\", \"pred_next_28_inv\", \"initial_inventory_inv\", \"inventory_score_inv\"\n",
    "]]\n",
    "\n",
    "# rename columns for clarity\n",
    "final_df = final_df.rename(columns={\n",
    "    \"pred_next_28_inv\": \"predicted_sales_next_28_days\",\n",
    "    \"initial_inventory_inv\": \"initial_inventory\",\n",
    "    \"inventory_score_inv\": \"inventory_score\"\n",
    "})\n",
    "\n",
    "# save final dataset\n",
    "out_path = r\"D:\\CAPSTONE_FINAL\\data\\final_merged_inventory_sentiment.csv\"\n",
    "final_df.to_csv(out_path, index=False)\n",
    "print(f\" Cleaned dataset saved -> {out_path}\")\n",
    "print(\"Shape:\", final_df.shape)\n",
    "display(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b35259cf-fad0-4b7e-9d39-4a285cce839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column\tDescription\n",
    "\n",
    "#item_id\tUnique product identifier (from sentiment side)\n",
    "#title\tProduct name\n",
    "#category\tProduct category (Electronics here)\n",
    "#avg_pos_prob\tAverage probability of positive sentiment\n",
    "#pos_ratio\tFraction of reviews labeled positive\n",
    "#neg_ratio\tFraction of reviews labeled negative\n",
    "#avg_rating\tAverage user rating\n",
    "#predicted_sales_next_28_days\tForecasted sales from LightGBM\n",
    "#initial_inventory\tCurrent stock available\n",
    "#inventory_score\tModel-predicted inventory efficiency or health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71508f37-4b33-4ac2-8742-1d5ea5a98cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone311 (py3.11)",
   "language": "python",
   "name": "capstone311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
